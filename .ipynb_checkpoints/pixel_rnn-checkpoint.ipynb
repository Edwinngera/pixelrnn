{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is using MNIST dataset for testing purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Importing dataset with TensorFlow built-in fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Creating functions for PixelRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSTM_layer(lstm_cell_units, number_of_layers, batch_size, dropout_rate=0.8):\n",
    "    '''\n",
    "    This method is used to create LSTM layer/s for PixelRNN\n",
    "    \n",
    "    Input(s): lstm_cell_unitis - used to define the number of units in a LSTM layer\n",
    "              number_of_layers - used to define how many of LSTM layers do we want in the network\n",
    "              batch_size - in this method this information is used to build starting state for the network\n",
    "              dropout_rate - used to define how many cells in a layer do we want to 'turn off'\n",
    "              \n",
    "    Output(s): cell - lstm layer\n",
    "               init_state - zero vectors used as a starting state for the network\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    layer = tf.contrib.rnn.BasicLSTMCell(lstm_cell_units)\n",
    "    \n",
    "    if dropout_rate != 0:\n",
    "        layer = tf.contrib.rnn.DropoutWrapper(layer, dropout_rate)\n",
    "        \n",
    "    cell = tf.contrib.rnn.MultiRNNCell([layer]*number_of_layers)\n",
    "    \n",
    "    init_size = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    return cell, init_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_output(lstm_outputs, input_size, output_size):\n",
    "    '''\n",
    "    Output layer for the lstm netowrk\n",
    "    \n",
    "    Input(s): lstm_outputs - outputs from the RNN part of the network\n",
    "              input_size - in this case it is RNN size (number of neuros in RNN layer)\n",
    "              output_size - number of neuros for the output layer == number of classes\n",
    "              \n",
    "    Output(s) - logits, \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    outputs = lstm_outputs[:, -1, :]\n",
    "    \n",
    "    weights = tf.Variable(tf.random_uniform([input_size, output_size]), name='rnn_out_weights')\n",
    "    bias = tf.Variable(tf.zeros([output_size]), name='rnn_out_bias')\n",
    "    \n",
    "    output_layer = tf.matmul(outputs, weights) + bias\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_optimizer(rnn_out, targets, learning_rate):\n",
    "    '''\n",
    "    Function used to calculate loss and minimize it\n",
    "    \n",
    "    Input(s): rnn_out - logits from the fully_connected layer\n",
    "              targets - targets used to train network\n",
    "              learning_rate/step_size\n",
    "    \n",
    "    \n",
    "    Output(s): optimizer - optimizer of choice\n",
    "               loss - calculated loss function\n",
    "    '''\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=rnn_out, labels=targets)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return optimizer, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PixelRNN(object):\n",
    "    \n",
    "    def __init__(self, learning_rate=0.001, batch_size=100, classes=10, img_size = (28, 28), lstm_size=128,\n",
    "                number_of_layers=1, dropout_rate=0.6):\n",
    "        \n",
    "        '''\n",
    "        PixelRNN - call this class to create whole model\n",
    "        \n",
    "        Input(s): learning_rate - how fast are we going to move towards global minima\n",
    "                  batch_size - how many samples do we feed at ones\n",
    "                  classes - number of classes that we are trying to recognize\n",
    "                  img_size - width and height of a single image\n",
    "                  lstm_size - number of neurons in a LSTM layer\n",
    "                  number_of_layers - number of RNN layers in the PixelRNN \n",
    "                  dropout_rate - % of cells in a layer that we are stopping gradients to flow through\n",
    "        '''\n",
    "        \n",
    "        #This placeholders are just for images\n",
    "        self.inputs = tf.placeholder(tf.float32, [None, img_size[0], img_size[1]], name='inputs')\n",
    "        self.targets = tf.placeholder(tf.int32, [None, classes], name='targets')\n",
    "        \n",
    "        cell, init_state = LSTM_layer(lstm_size, number_of_layers, batch_size, dropout_rate)\n",
    "        \n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, self.inputs, initial_state=init_state)\n",
    "        \n",
    "        rnn_out = rnn_output(outputs, lstm_size, classes)\n",
    "        \n",
    "        self.opt, self.cost = loss_optimizer(rnn_out, self.targets, learning_rate, clip_rate)\n",
    "        \n",
    "        predictions = tf.nn.softmax(rnn_out)\n",
    "        \n",
    "        currect_pred = tf.equal(tf.cast(tf.round(tf.argmax(predictions, 1)), tf.int32), tf.cast(tf.argmax(self.targets, 1), tf.int32))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(currect_pred, tf.float32))\n",
    "        \n",
    "        self.predictions = tf.argmax(tf.nn.softmax(rnn_out), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = PixelRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 81.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/20  | Current loss: 0.5176992416381836  | Training accuracy: 0.8269%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9079%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 82.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20  | Current loss: 0.19001635909080505  | Training accuracy: 0.9394%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9651%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 83.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20  | Current loss: 0.1403244584798813  | Training accuracy: 0.9545%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9597%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 83.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20  | Current loss: 0.11507342010736465  | Training accuracy: 0.9629%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9673%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 82.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20  | Current loss: 0.09507040679454803  | Training accuracy: 0.9687%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9881%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 83.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20  | Current loss: 0.08376456797122955  | Training accuracy: 0.9722%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9594%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 83.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20  | Current loss: 0.07862323522567749  | Training accuracy: 0.9747%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9853%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 85.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20  | Current loss: 0.06911516189575195  | Training accuracy: 0.9780%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9825%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:07<00:00, 78.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/20  | Current loss: 0.06478450447320938  | Training accuracy: 0.9794%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9740%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:07<00:00, 81.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20  | Current loss: 0.06400001049041748  | Training accuracy: 0.9796%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9605%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 81.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20  | Current loss: 0.05679477006196976  | Training accuracy: 0.9820%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9847%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:07<00:00, 75.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/20  | Current loss: 0.057584892958402634  | Training accuracy: 0.9809%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9895%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 83.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20  | Current loss: 0.05209050700068474  | Training accuracy: 0.9831%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9754%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 82.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20  | Current loss: 0.047683075070381165  | Training accuracy: 0.9844%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9837%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 83.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20  | Current loss: 0.04920829460024834  | Training accuracy: 0.9838%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9806%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 82.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/20  | Current loss: 0.047188419848680496  | Training accuracy: 0.9846%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9926%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 83.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/20  | Current loss: 0.04569714516401291  | Training accuracy: 0.9851%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9717%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 84.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20  | Current loss: 0.04454415664076805  | Training accuracy: 0.9855%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9970%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 83.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/20  | Current loss: 0.0410366915166378  | Training accuracy: 0.9870%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9824%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 550/550 [00:06<00:00, 81.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/20  | Current loss: 0.03961211070418358  | Training accuracy: 0.9871%\n",
      "\n",
      " TESTING PROCESS...\n",
      "Testing accuracy is: 0.9890%\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 100\n",
    "image_vector = 28*28\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    training_accuracy = []\n",
    "    epoch_loss = []\n",
    " \n",
    "    for ii in tqdm(range(mnist.train.num_examples // batch_size)):\n",
    "        \n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        images = batch[0].reshape((-1, 28, 28))\n",
    "        targets = batch[1]\n",
    "        \n",
    "        c, _, a = session.run([model.cost, model.opt, model.accuracy], feed_dict={model.inputs: images, model.targets:targets})\n",
    "        \n",
    "        epoch_loss.append(c)\n",
    "        training_accuracy.append(a)\n",
    "        \n",
    "    print(\"Epoch: {}/{}\".format(i, epochs), \" | Current loss: {}\".format(np.mean(epoch_loss)),\n",
    "          \" | Training accuracy: {:.4f}%\".format(np.mean(training_accuracy)))\n",
    "    \n",
    "    print('\\n', 'TESTING PROCESS...')\n",
    "    \n",
    "    testing_accuracy = []\n",
    "    for k in range(mnist.test.num_examples // batch_size):\n",
    "        \n",
    "        batch_test = mnist.test.next_batch(batch_size)\n",
    "        \n",
    "        images_test = batch[0].reshape((-1, 28, 28))\n",
    "        targets_test = batch[1]\n",
    "        \n",
    "        ta = session.run([model.accuracy], feed_dict={model.inputs: images_test, model.targets:targets_test})\n",
    "        testing_accuracy.append(ta)\n",
    "        \n",
    "    print(\"Testing accuracy is: {:.4f}%\".format(np.mean(testing_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
